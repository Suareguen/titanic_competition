{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(columns=\"Cabin\")\n",
    "# data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "# data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "\n",
    "# data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apply con una función lambda\n",
    "data['Sex'] = data['Sex'].apply(lambda x: 1 if x == 'female' else 0).astype(int)\n",
    "# data['Sex'] = data['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    891.000000\n",
      "mean      28.476992\n",
      "std        9.793559\n",
      "min        3.000000\n",
      "25%       23.750000\n",
      "50%       28.000000\n",
      "75%       33.000000\n",
      "max       54.000000\n",
      "Name: Age, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   PassengerId       891 non-null    int64  \n",
      " 1   Survived          891 non-null    int64  \n",
      " 2   Pclass            891 non-null    int64  \n",
      " 3   Name              891 non-null    object \n",
      " 4   Sex               891 non-null    int64  \n",
      " 5   Age               891 non-null    float64\n",
      " 6   SibSp             891 non-null    int64  \n",
      " 7   Parch             891 non-null    int64  \n",
      " 8   Ticket            891 non-null    object \n",
      " 9   Fare              891 non-null    float64\n",
      " 10  Embarked          891 non-null    object \n",
      " 11  Embarked_encoded  891 non-null    float64\n",
      " 12  FlagSolo          891 non-null    int64  \n",
      "dtypes: float64(3), int64(7), object(3)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Q1 = data['Age'].quantile(0.25)  # Primer cuartil (25%)\n",
    "Q3 = data['Age'].quantile(0.75)  # Tercer cuartil (75%)\n",
    "IQR = Q3 - Q1  \n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR  \n",
    "upper_bound = Q3 + 1.5 * IQR  \n",
    "\n",
    "median_age = data['Age'].median()\n",
    "data['Age'] = data['Age'].apply(lambda x: median_age if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "print(data['Age'].describe())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "data['Embarked_encoded'] = encoder.fit_transform(data[['Embarked']])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numeric_columns = data.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "numeric_column_names = numeric_columns.columns.tolist()\n",
    "print(\"Numeric Column Names:\", numeric_column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_grouped_by_sex = data.groupby(by=['Survived', 'Sex']).count().unstack(level=0)['PassengerId']\n",
    "print(survival_grouped_by_sex)\n",
    "survival_grouped_by_sex.plot.bar()\n",
    "survival_grouped_by_sex_1 = data.groupby(by=['Survived', 'Sex']).count()['PassengerId']\n",
    "survival_grouped_by_sex_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Pclass\", y='Survived', data=data, hue=data['Sex'])\n",
    "plt.show()\n",
    "sns.barplot(x=\"Pclass\", y='Survived', data=data, hue=data['Pclass'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"SibSp\", y='Survived', data=data, hue=data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Parch\", y='Survived', data=data, hue=data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['FlagSolo'] = np.where(\n",
    "    (data['SibSp'] == 0) & (data['Parch'] == 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data[data['Survived'] == 1]['Age'], bins=30, kde=True, color=\"blue\", label=\"Survived = 1\", alpha=0.6)\n",
    "plt.title(\"Distribución de Edad para Supervivientes\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data[data['Survived'] == 0]['Age'], bins=30, kde=True, color=\"red\", label=\"Survived = 0\", alpha=0.6)\n",
    "plt.title(\"Distribución de Edad para No Supervivientes\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean = data.groupby(\"Survived\")[\"Age\"].mean()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "age_mean.plot(kind='bar', color=[\"red\", \"blue\"], alpha=0.7)\n",
    "plt.title(\"Promedio de Edad por Supervivencia\")\n",
    "plt.xlabel(\"Survived (0 = No, 1 = Sí)\")\n",
    "plt.ylabel(\"Edad Promedio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numeric_columns = data.select_dtypes(include=['number'])\n",
    "\n",
    "\n",
    "numeric_column_names = numeric_columns.columns.tolist()\n",
    "print(\"Numeric Column Names:\", numeric_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = data[numeric_column_names].corr()\n",
    "\n",
    "# Mostrar la matriz de correlación\n",
    "\n",
    "# Configurar el tamaño del gráfico\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Crear el heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "\n",
    "# Añadir título\n",
    "plt.title(\"Heatmap de Correlación entre Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation of all features with the target variable 'MedHouseVal'\n",
    "correlation_with_target = data[numeric_column_names].corr()['Survived'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the correlations\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -0.6091447105050983, P-value: 0.5425841552024884\n",
      "Age and Survived not relationed\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group_survived = data[data['Survived'] == 1]['Age'].dropna()\n",
    "group_not_survived = data[data['Survived'] == 0]['Age'].dropna()\n",
    "\n",
    "t_stat, p_value = ttest_ind(group_survived, group_not_survived)\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Age and Survived relationed\")\n",
    "else:\n",
    "    print(\"Age and Survived not relationed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Select relevant features for VIF calculation\n",
    "X = data[numeric_column_names]\n",
    "X = X.drop(columns=[\"PassengerId\", \"Survived\", \"Parch\", \"SibSp\", \"Age\"])\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))\n",
    "\n",
    "# No existe multicolinealidad en exceso // Mantenemos las caracteristicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "target = data['Survived']\n",
    "# selected_features = ['Pclass', 'Sex', 'Age', 'FlagSolo', 'Fare', 'Embarked_encoded']\n",
    "\n",
    "data_selected = data[numeric_column_names]\n",
    "\n",
    "\n",
    "# Filter Method for Feature Selection\n",
    "selector = SelectKBest(score_func=f_classif, k=5)\n",
    "selected_features = selector.fit_transform(data_selected, target)\n",
    "\n",
    "print(\"Selected Features Shape:\", selected_features.shape)\n",
    "selected_feature_names = data_selected.columns[selector.get_support()]\n",
    "print(\"Selected Feature Names:\", selected_feature_names)\n",
    "data[selected_feature_names].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = data['Survived'].value_counts()\n",
    "\n",
    "class_counts.plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title(\"Balance de clases en 'Survived'\")\n",
    "plt.xlabel(\"Clase\")\n",
    "plt.ylabel(\"Número de instancias\")\n",
    "plt.xticks(ticks=[0, 1], labels=['No sobrevivió', 'Sobrevivió'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = data['Survived']\n",
    "X = data[selected_feature_names].drop(columns='Survived')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(y_train.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Crear el Pipeline con un paso genérico para el modelo\n",
    "pipeline = Pipeline([\n",
    "    ('model', RandomForestClassifier(random_state=42))  # Este será sustituido en el GridSearch\n",
    "])\n",
    "\n",
    "# Definir los hiperparámetros para cada modelo\n",
    "param_grid = [\n",
    "    {\n",
    "        'model': [RandomForestClassifier(random_state=42, class_weight=\"balanced\")],\n",
    "        'model__n_estimators': [10, 50, 150, 200],\n",
    "        'model__max_depth': [None, 10, 50, 150],\n",
    "        'model__max_leaf_nodes': [10, 30, 50, 70],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 3, 4],\n",
    "        'model__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    {\n",
    "        'model': [LogisticRegression(random_state=42, max_iter=500)],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "    {\n",
    "        'model': [SVC(random_state=42)],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf'],\n",
    "        'model__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    {\n",
    "        'model': [DecisionTreeClassifier(random_state=42)],\n",
    "        'model__max_depth': [10, 50, 150, 200],\n",
    "        'model__max_leaf_nodes': [10, 30, 50, 70],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 3, 4],\n",
    "        'model__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configurar el GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # Validación cruzada\n",
    "    scoring='accuracy',  # Métrica a optimizar\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Usar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Ejecutar el GridSearch\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros y el modelo ganador\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "print(\"Best Model:\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, recall_score, f1_score, precision_score\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Mostrar la matriz de confusión con visualización\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=best_model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, average='binary')\n",
    "recall = recall_score(y_val, y_pred, average='binary')\n",
    "f1 = f1_score(y_val, y_pred, average='binary')\n",
    "\n",
    "# Mostrar las métricas\n",
    "print(f\"{best_model}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "selected_features = ['Pclass', 'Sex', 'Fare', 'FlagSolo']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "# ahora hay que preparar el test set para evaluación\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "# preprocesando test set\n",
    "test['Embarked_encoded'] = encoder.fit_transform(test[['Embarked']])\n",
    "\n",
    "# hacer map a Sex\n",
    "test['Sex'] = test['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "\n",
    "# rellenar Age\n",
    "test['Age'] = test['Age'].fillna(28.0)\n",
    "\n",
    "# Crear FlagSolo\n",
    "test['FlagSolo'] = np.where(\n",
    "    (test['SibSp'] == 0) & (test['Parch'] == 0), 1, 0)\n",
    "test[selected_features].head(3)\n",
    "# crear test set \n",
    "X_test = test[selected_features]\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.head())\n",
    "\n",
    "# prediccion de Survived en test set\n",
    "Y_pred_rf = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciendo sobre el test set\n",
    "print(Y_pred_rf[0:20])\n",
    "# para descargar en ordenador\n",
    "def download_output(y_pred, name):\n",
    "  output = pd.DataFrame({'PassengerId': test.PassengerId, \n",
    "                         'Survived': y_pred})\n",
    "  output.to_csv(name, index=False)\n",
    "download_output(Y_pred_rf, 'ml_prediction.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
